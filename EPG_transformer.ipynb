{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset, ConcatDataset, SubsetRandomSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import time\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "import math \n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "aqHPuDlSM6qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Generate_Data(number):\n",
        "     data = torch.FloatTensor(number,1,100).uniform_(1,5)\n",
        "     return data \n",
        "\n",
        "def Generate_label(number):\n",
        "     data = torch.randint(low=0, high=2, size=(number,100), dtype=torch.float)\n",
        "     data = data.to(torch.int64)\n",
        "     return data "
      ],
      "metadata": {
        "id": "0aEaH5p4NvwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = Generate_Data(400)\n",
        "train_y = Generate_label(400)\n",
        "\n",
        "test_x = Generate_Data(80)\n",
        "test_y = Generate_label(80)"
      ],
      "metadata": {
        "id": "vYEYhzSlQwZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing 時不需做 data augmentation\n",
        "train_transform = transforms.Compose([    \n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([ \n",
        "    transforms.ToPILImage(),   \n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "class EPG_Dataset(Dataset):\n",
        "    def __init__(self, x, y, transform=None):\n",
        "        self.x = x\n",
        "        # label is required to be a LongTensor\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    def __getitem__(self, index):\n",
        "        X = self.x[index]\n",
        "        if self.transform is not None:\n",
        "            X = self.transform(X)\n",
        "            Y = self.y[index]\n",
        "            return X, Y"
      ],
      "metadata": {
        "id": "rk0RWlTaP9Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 30\n",
        "\n",
        "train_set = EPG_Dataset(train_x, train_y, train_transform)\n",
        "test_set = EPG_Dataset(test_x, test_y, test_transform)\n",
        "print(\"Size of training data = {}\".format(len(train_x)))\n",
        "print(\"Size of testing data = {}\".format(len(test_x)))\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwFQuxJmQb2O",
        "outputId": "bd498ff0-a7ab-4551-81d5-b798110a2ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training data = 400\n",
            "Size of testing data = 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EPG_CNN_RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EPG_CNN_RNN, self).__init__()\n",
        "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
        "        # input 維度 [100]\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, 1, 1),  #[32, 50]\n",
        "            nn.MaxPool2d(1, 2, 0),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.Conv2d(32, 64, 3, 1, 1),  #[64, 25]\n",
        "            nn.MaxPool2d(1, 2, 0),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),   \n",
        "        )       \n",
        "\n",
        "        self.rnn = nn.RNN(64*25, 600, 2, batch_first=True)\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(600, 300),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(300, 200),\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cnn(x)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        #out = self.rnn(out)\n",
        "        #out = out[0][:, -1, :]\n",
        "        out, _ = self.rnn(out.unsqueeze(0))\n",
        "        out = self.fc(out.squeeze(0))\n",
        "        #out = self.fc(out)\n",
        "        out = out.view(out.size()[0], 100, 2)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "4jUnoWIbYOZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EPG_CNN_RNN().cuda()\n",
        "#model.load_state_dict(torch.load('./model_ep?.pt'))\n",
        "loss = nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005) \n",
        "num_epoch = 25\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    epoch_start_time = time.time()\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "\n",
        "    model.train()\n",
        "    for i, data in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        train_pred = model(data[0].cuda())\n",
        "        batch_loss = loss(train_pred.view(-1,2), data[1].view(-1).cuda())\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        #print(np.argmax(train_pred.cpu().data.numpy(), axis=2))\n",
        "        #print(data[1].numpy())\n",
        "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=2) == data[1].numpy())\n",
        "        train_loss += batch_loss.item()\n",
        "\n",
        "\n",
        "    print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f' % \\\n",
        "      (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
        "      train_acc/(train_set.__len__()*100), train_loss/(train_set.__len__()*100)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8NJagXlSGos",
        "outputId": "c5055cec-e42c-491f-8a45-cd58d28f7e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[001/025] 0.14 sec(s) Train Acc: 0.501175 Loss: 0.000243\n",
            "[002/025] 0.15 sec(s) Train Acc: 0.544250 Loss: 0.000240\n",
            "[003/025] 0.15 sec(s) Train Acc: 0.621975 Loss: 0.000232\n",
            "[004/025] 0.15 sec(s) Train Acc: 0.681350 Loss: 0.000219\n",
            "[005/025] 0.14 sec(s) Train Acc: 0.731925 Loss: 0.000203\n",
            "[006/025] 0.15 sec(s) Train Acc: 0.765125 Loss: 0.000185\n",
            "[007/025] 0.16 sec(s) Train Acc: 0.792375 Loss: 0.000169\n",
            "[008/025] 0.14 sec(s) Train Acc: 0.819075 Loss: 0.000154\n",
            "[009/025] 0.15 sec(s) Train Acc: 0.846125 Loss: 0.000139\n",
            "[010/025] 0.14 sec(s) Train Acc: 0.872100 Loss: 0.000124\n",
            "[011/025] 0.14 sec(s) Train Acc: 0.891825 Loss: 0.000111\n",
            "[012/025] 0.14 sec(s) Train Acc: 0.905175 Loss: 0.000101\n",
            "[013/025] 0.14 sec(s) Train Acc: 0.924200 Loss: 0.000090\n",
            "[014/025] 0.14 sec(s) Train Acc: 0.934750 Loss: 0.000082\n",
            "[015/025] 0.14 sec(s) Train Acc: 0.947375 Loss: 0.000073\n",
            "[016/025] 0.14 sec(s) Train Acc: 0.954775 Loss: 0.000066\n",
            "[017/025] 0.15 sec(s) Train Acc: 0.961650 Loss: 0.000061\n",
            "[018/025] 0.14 sec(s) Train Acc: 0.968050 Loss: 0.000055\n",
            "[019/025] 0.14 sec(s) Train Acc: 0.971100 Loss: 0.000051\n",
            "[020/025] 0.16 sec(s) Train Acc: 0.976050 Loss: 0.000046\n",
            "[021/025] 0.25 sec(s) Train Acc: 0.976050 Loss: 0.000043\n",
            "[022/025] 0.18 sec(s) Train Acc: 0.984000 Loss: 0.000038\n",
            "[023/025] 0.18 sec(s) Train Acc: 0.985800 Loss: 0.000034\n",
            "[024/025] 0.18 sec(s) Train Acc: 0.992350 Loss: 0.000030\n",
            "[025/025] 0.18 sec(s) Train Acc: 0.993775 Loss: 0.000027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_acc, test_loss = 0.0,0\n",
        "with torch.no_grad():\n",
        "        for i, data in enumerate(test_loader):\n",
        "            test_pred = model(data[0].cuda())\n",
        "            batch_loss = loss(test_pred.view(-1,2), data[1].view(-1).cuda())\n",
        "            \n",
        "            test_acc += np.sum(np.argmax(test_pred.cpu().data.numpy(), axis=2) == data[1].numpy())\n",
        "            test_loss += batch_loss.item()\n",
        "\n",
        "print(\"Test Acc:{}, Test Loss:{}\".format(test_acc/(test_set.__len__()*100), test_loss/(test_set.__len__()*100)))"
      ],
      "metadata": {
        "id": "IsqdUzKnSMGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "878524a7-b868-43e2-8270-d7f523d7a998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc:0.492625, Test Loss:0.0005852205157279968\n"
          ]
        }
      ]
    }
  ]
}